{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from time import time\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/james/Documents/Data/genre classification/' \n",
    "AUDIO_DIR = DATA_DIR + 'Audio' \n",
    "NPZ_DIR = DATA_DIR + 'npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "N_MFCC = 20\n",
    "POOL_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downloaded_track_ids(directory):\n",
    "    \"\"\"\n",
    "    Collect the track_ids from the tracks that have downloaded in the specific directory\n",
    "    :return: ist of track ids\n",
    "    \"\"\"    \n",
    "    track_ids = []\n",
    "    for _, dirnames, files in os.walk(directory):\n",
    "        if dirnames == []:\n",
    "            track_ids.extend(str(file[:-4]) for file in files) # 4 spots before the '.mp3'\n",
    "    return track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_path(directory, track_id):\n",
    "    \"\"\"\n",
    "    Return the path to the mp3 given the directory where the audio is stored\n",
    "    and the track ID.\n",
    "    \"\"\"\n",
    "    return os.path.join(directory, track_id + '.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the successfully downloaded track id's  \n",
    "track_ids = get_downloaded_track_ids(AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mfcc(track_id):\n",
    "    filename = get_audio_path(AUDIO_DIR, track_id)\n",
    "    y, sr = librosa.load(filename)\n",
    "    spect = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC)\n",
    "    return spect.T  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'club': 0, 'bass-other': 1}\n"
     ]
    }
   ],
   "source": [
    "# load the meta data from data transformer step\n",
    "meta_data_df = pd.read_pickle(DATA_DIR + '/meta_data.pkl')\n",
    "\n",
    "genre_target_list = meta_data_df['genre_target'].unique()\n",
    "genre_target_dict = {genre_target_list[i] : i  for i in range(0,len(genre_target_list))}\n",
    "print(genre_target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_label_array(df):\n",
    "    genres = []\n",
    "    X_spect = np.empty((0, 640, N_MFCC))\n",
    "    count = 0\n",
    "    #Code skips records in case of errors\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            count += 1\n",
    "            track_id = row['guid']\n",
    "            genre = str(row['genre_target'])\n",
    "            spect = create_mfcc(track_id)\n",
    "\n",
    "            # Normalize for small shape differences\n",
    "            spect = spect[:640, :]\n",
    "            X_spect = np.append(X_spect, [spect], axis=0)\n",
    "            genres.append(genre_target_dict[genre])\n",
    "            if count % 100 == 0:\n",
    "                print(\"Currently processing: \", count)\n",
    "        except:\n",
    "            print(\"Couldn't process: \", count)\n",
    "            continue\n",
    "    y = np.array(genres)\n",
    "    return X_spect , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_feature_label_creation(df, pool_size):\n",
    "    \"\"\"\n",
    "    process the 'create_features_..' function in pools across multiple cores \n",
    "    \"\"\"\n",
    "    df_split = np.array_split(df, pool_size)\n",
    "    pool = multiprocessing.Pool(processes=pool_size)\n",
    "    results = pool.map(create_features_label_array, df_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    X_spect = [result[0] for result in results]\n",
    "    y = [result[1] for result in results]\n",
    "    \n",
    "    X_spect = np.vstack(X_spect)\n",
    "    y = np.concatenate(y)\n",
    "    \n",
    "    return X_spect, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2024, 4) (579, 4) (289, 4)\n"
     ]
    }
   ],
   "source": [
    "# create\n",
    "df_train = meta_data_df[meta_data_df['split'] == 'train']\n",
    "df_valid = meta_data_df[meta_data_df['split'] == 'valid']\n",
    "df_test  = meta_data_df[meta_data_df['split'] == 'test']\n",
    "\n",
    "print(df_train.shape, df_valid.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  100\n",
      "Currently processing:  100\n",
      "Currently processing:  100\n",
      "Currently processing:  100\n",
      "Currently processing:  100\n",
      "Currently processing:  100\n",
      "Currently processing:  100\n",
      "Currently processing:  100\n",
      "Currently processing:  200\n",
      "Currently processing:  200\n",
      "Currently processing:  200\n",
      "Currently processing:  200\n",
      "Currently processing:  200\n",
      "Currently processing:  200\n",
      "Currently processing:  200\n",
      "Currently processing:  200\n",
      "(2024, 640, 20) (2024,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = parallel_feature_label_creation(df_train, POOL_SIZE)\n",
    "print(X_train.shape, y_train.shape)\n",
    "np.savez(NPZ_DIR + '/MFC_train_array', X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  100\n",
      "Currently processing:  200\n",
      "Currently processing:  300\n",
      "Currently processing:  400\n",
      "Currently processing:  500\n",
      "(579, 640, 20) (579,)\n"
     ]
    }
   ],
   "source": [
    "X_valid, y_valid = create_features_label_array(df_valid)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "np.savez(NPZ_DIR + '/MFC_valid_array', X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing:  100\n",
      "Currently processing:  200\n",
      "(289, 640, 20) (289,)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = create_features_label_array(df_test)\n",
    "print(X_test.shape, y_test.shape)\n",
    "np.savez(NPZ_DIR + '/MFC_test_array', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1']\n",
      "(2024, 640, 20) (2024,)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load(NPZ_DIR + '/MFC_train_array.npz')\n",
    "print(npzfile.files)\n",
    "X_train = npzfile['arr_0']\n",
    "y_train = npzfile['arr_1']\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1']\n",
      "(579, 640, 20) (579,)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load(NPZ_DIR + '/MFC_valid_array.npz')\n",
    "print(npzfile.files)\n",
    "X_valid = npzfile['arr_0']\n",
    "y_valid = npzfile['arr_1']\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFCC Summary Stats (each mfcc band averaged over time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, standard dev, skew, kurtosis, median, min, max\n",
    "def mfcc_summary(X_array, time_axis=1):\n",
    "    X_copy = X_array.copy()\n",
    "    x1 = np.mean(X_copy, axis=time_axis)\n",
    "    x2 = np.std(X_copy, axis=time_axis)\n",
    "    x3 = stats.skew(X_copy, axis=time_axis)\n",
    "    x4 = stats.kurtosis(X_copy, axis=time_axis)\n",
    "    x5 = np.median(X_copy, axis=time_axis)\n",
    "    x6 = np.min(X_copy, axis=time_axis)\n",
    "    x7 = np.max(X_copy, axis=time_axis)\n",
    "    \n",
    "    X_summary = np.concatenate([x1,x2,x3,x4,x5,x6,x7], axis=1)\n",
    "    \n",
    "    return X_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2024, 140)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stats_array = mfcc_summary(X_train, 1)\n",
    "X_train_stats_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 140)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_stats_array = mfcc_summary(X_valid, 1)\n",
    "X_valid_stats_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Features and Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle training features\n",
    "X_train_stats_array, y_train = skl.utils.shuffle(X_train_stats_array, y_train, random_state=17)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance using x_train as model fit and applyimng to hold-out and validation sets\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "X_train = scaler.fit_transform(X_train_stats_array)\n",
    "X_valid = scaler.transform(X_valid_stats_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_valid = le.fit_transform(y_valid)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 140)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target, y_pred, average='micro', pos_label = 1)\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print(\"F1 score for val set: {:.4f}.\".format(predict_labels(clf, X_valid, y_valid)))\n",
    "    #print(\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeClassifier: \n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 2024. . .\n",
      "Trained model in 0.0980 seconds\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for training set: 0.6838.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for val set: 0.5889.\n",
      "\n",
      "SVC: \n",
      "\n",
      "Training a SVC using a training set size of 2024. . .\n",
      "Trained model in 0.5364 seconds\n",
      "Made predictions in 0.4361 seconds.\n",
      "F1 score for training set: 0.8394.\n",
      "Made predictions in 0.1304 seconds.\n",
      "F1 score for val set: 0.6615.\n",
      "\n",
      "LogisticRegression: \n",
      "\n",
      "Training a LogisticRegression using a training set size of 2024. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/Documents/Virtual Environments/deep-audio-env/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.0857 seconds\n",
      "Made predictions in 0.0019 seconds.\n",
      "F1 score for training set: 0.7016.\n",
      "Made predictions in 0.0002 seconds.\n",
      "F1 score for val set: 0.6131.\n",
      "\n",
      "RandomForestClassifier: \n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 2024. . .\n",
      "Trained model in 2.2633 seconds\n",
      "Made predictions in 0.0566 seconds.\n",
      "F1 score for training set: 0.9886.\n",
      "Made predictions in 0.0280 seconds.\n",
      "F1 score for val set: 0.6356.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Initialize the three models\n",
    "clf_A = DecisionTreeClassifier(random_state=10, max_depth =4)\n",
    "clf_B = SVC()\n",
    "clf_C = LogisticRegression()\n",
    "clf_D = RandomForestClassifier(random_state=10, max_depth=30, n_estimators=300, min_samples_leaf=6, min_impurity_decrease=0.0002,\n",
    "                     class_weight='balanced')\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D]:\n",
    "    print(\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    train_predict(clf, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
